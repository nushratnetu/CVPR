{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kj9En8VT9PMn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIq9Sbdt9Z-1",
        "outputId": "7c33132a-d50a-46ae-af6c-575a04c99a59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelAdam = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "modelSGD = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "modelRMSprop = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "modelAdam.compile(\n",
        "    optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']\n",
        "    )\n",
        "modelSGD.compile(\n",
        "    optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']\n",
        "    )\n",
        "modelRMSprop.compile(\n",
        "    optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "print(\"Model with ADAM\")\n",
        "historyAdam = modelAdam.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test))\n",
        "print(\" Model with SGD\")\n",
        "historySGD = modelSGD.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test))\n",
        "print(\"Model with  RMSprop\")\n",
        "historyRMSprop = modelRMSprop.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOb4XsGY9h4s",
        "outputId": "7b35b86d-1e16-451a-caf3-cbab0b668190"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with ADAM\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 71s 90ms/step - loss: 1.7818 - accuracy: 0.3903 - val_loss: 1.3566 - val_accuracy: 0.5135\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 1.2914 - accuracy: 0.5450 - val_loss: 1.2419 - val_accuracy: 0.5611\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 67s 86ms/step - loss: 1.1360 - accuracy: 0.5995 - val_loss: 1.2354 - val_accuracy: 0.5680\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 1.0227 - accuracy: 0.6421 - val_loss: 1.0918 - val_accuracy: 0.6183\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.9365 - accuracy: 0.6721 - val_loss: 1.1089 - val_accuracy: 0.6255\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 67s 86ms/step - loss: 0.8738 - accuracy: 0.6953 - val_loss: 1.0362 - val_accuracy: 0.6471\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 70s 89ms/step - loss: 0.8117 - accuracy: 0.7174 - val_loss: 1.0719 - val_accuracy: 0.6488\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 68s 87ms/step - loss: 0.7564 - accuracy: 0.7346 - val_loss: 1.0577 - val_accuracy: 0.6515\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.6872 - accuracy: 0.7596 - val_loss: 1.1007 - val_accuracy: 0.6456\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.6563 - accuracy: 0.7702 - val_loss: 1.0858 - val_accuracy: 0.6587\n",
            " Model with SGD\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 63s 80ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 67s 85ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 64s 82ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 63s 80ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 67s 85ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 65s 83ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 63s 80ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Model with  RMSprop\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 66s 83ms/step - loss: 1.8843 - accuracy: 0.3707 - val_loss: 1.5498 - val_accuracy: 0.4485\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 72s 92ms/step - loss: 1.3437 - accuracy: 0.5319 - val_loss: 1.3741 - val_accuracy: 0.5222\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 69s 88ms/step - loss: 1.1817 - accuracy: 0.5933 - val_loss: 1.4154 - val_accuracy: 0.5221\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 67s 86ms/step - loss: 1.0750 - accuracy: 0.6305 - val_loss: 1.3840 - val_accuracy: 0.5467\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 68s 87ms/step - loss: 0.9989 - accuracy: 0.6594 - val_loss: 1.2318 - val_accuracy: 0.5917\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 73s 93ms/step - loss: 0.9449 - accuracy: 0.6781 - val_loss: 1.1687 - val_accuracy: 0.6548\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 69s 88ms/step - loss: 0.8954 - accuracy: 0.6961 - val_loss: 1.6758 - val_accuracy: 0.5215\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 68s 87ms/step - loss: 0.8624 - accuracy: 0.7063 - val_loss: 1.3898 - val_accuracy: 0.5645\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 73s 93ms/step - loss: 0.8267 - accuracy: 0.7213 - val_loss: 1.2363 - val_accuracy: 0.6191\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 70s 90ms/step - loss: 0.8118 - accuracy: 0.7270 - val_loss: 1.2946 - val_accuracy: 0.6059\n"
          ]
        }
      ]
    }
  ]
}